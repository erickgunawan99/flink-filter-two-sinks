services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.3
    container_name: zookeeper
    networks:
      - flink-kafka-net
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ['CMD', 'cub', 'zk-ready', 'zookeeper:2181', '60']
      interval: 5s
      timeout: 5s
      retries: 5
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-log:/var/lib/zookeeper/log

  kafka:
    image: confluentinc/cp-kafka:7.0.3
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    networks:
      - flink-kafka-net
    ports:
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      # KAFKA_CREATE_TOPICS IS INTENTIONALLY REMOVED - the setup service handles it now
    volumes:
      - kafka-data:/var/lib/kafka/data

  kafka-setup:
    image: confluentinc/cp-kafka:7.0.1
    container_name: kafka_setup
    depends_on:
      - kafka
    networks:
      - flink-kafka-net
    command: >
      bash -c "
        echo 'Waiting for Kafka to be ready...' &&
        cub kafka-ready -b kafka:9092 1 120 &&
        echo 'Kafka is ready.' &&
        echo 'Creating topic user_events...' &&
        kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic user_events --partitions 2 --replication-factor 1 &&
        echo 'Topic created successfully.'
      "

  jobmanager:
    build: .
    container_name: jobmanager
    # ... (rest of your file is the same)
    command: jobmanager
    ports:
      - "8081:8081"
      - "6123:6123"
    volumes:
      - ./plugins/flink-s3-fs-hadoop-1.20.0.jar:/opt/flink/lib/flink-s3-fs-hadoop-1.20.0.jar
      - flink-data:/opt/flink/data
    networks:
      - flink-kafka-net
    environment:
      AWS_ACCESS_KEY_ID: admin
      AWS_SECRET_ACCESS_KEY: admin123
      AWS_REGION: us-east-1
      S3_ENDPOINT: http://minio:9000
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: jobmanager
        rest.address: 0.0.0.0
        rest.bind-address: 0.0.0.0
        rest.port: 8081
        jobmanager.memory.process.size: 1024m
        s3.endpoint: http://minio:9000
        s3.path.style.access: true
        s3.access.key: admin
        s3.secret.key: admin123
        s3.region: us-east-1

  taskmanager:
    build: .
    container_name: taskmanager
    command: taskmanager
    depends_on:
      - jobmanager
      - minio
      - kafka
    volumes:
      - ./plugins/flink-s3-fs-hadoop-1.20.0.jar:/opt/flink/lib/flink-s3-fs-hadoop-1.20.0.jar
      - flink-data:/opt/flink/data
    networks:
      - flink-kafka-net
    environment:
      AWS_ACCESS_KEY_ID: admin
      AWS_SECRET_ACCESS_KEY: admin123
      AWS_REGION: us-east-1
      S3_ENDPOINT: http://minio:9000
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: jobmanager
        taskmanager.memory.process.size: 2048m
        taskmanager.memory.managed.fraction: 0.5
        taskmanager.numberOfTaskSlots: 2
        s3.endpoint: http://minio:9000
        s3.path.style.access: true
        s3.access.key: admin
        s3.secret.key: admin123
        s3.region: us-east-1

  minio:
    image: quay.io/minio/minio:latest
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    networks:
      - flink-kafka-net
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: admin123
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data

volumes:
  minio-data:
  flink-data:
  kafka-data:
  zookeeper-data:
  zookeeper-log:

networks:
  flink-kafka-net:
    driver: bridge